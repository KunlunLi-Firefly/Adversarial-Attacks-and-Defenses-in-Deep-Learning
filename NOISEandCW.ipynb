{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f9e57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\kun\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kun\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kun\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\kun\\anaconda3\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\kun\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kun\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\kun\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kun\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kun\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeee5ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 170498071/170498071 [00:05<00:00, 28969794.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Set up transformations: normalizing and converting to tensor\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load the training and test sets\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Define classes in CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab67454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple CNN\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a336908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 2000: Loss: 2.286\n",
      "Epoch 1, Batch 4000: Loss: 2.008\n",
      "Epoch 1, Batch 6000: Loss: 1.758\n",
      "Epoch 1, Batch 8000: Loss: 1.617\n",
      "Epoch 1, Batch 10000: Loss: 1.549\n",
      "Epoch 1, Batch 12000: Loss: 1.496\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def train_network(net, trainloader, criterion, optimizer, epochs=1):\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}: Loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "# Call the training function\n",
    "train_network(net, trainloader, criterion, optimizer, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d7eb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 46.30%\n",
      "Average loss on the test images: 1.4625\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(net, dataloader, criterion, device='cpu'):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    avg_loss = test_loss / len(dataloader)\n",
    "    print(f'Accuracy of the network on the test images: {accuracy:.2f}%')\n",
    "    print(f'Average loss on the test images: {avg_loss:.4f}')\n",
    "    return accuracy, avg_loss\n",
    "\n",
    "# Evaluate the model without any attacks\n",
    "accuracy, avg_loss = evaluate_model(net, testloader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203bd5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_attack(image, epsilon):\n",
    "    \"\"\"Apply Gaussian noise attack to the input image.\"\"\"\n",
    "    # Adding noise scaled by epsilon\n",
    "    noise = epsilon * torch.randn_like(image)\n",
    "    # Adding the noise to the original image \n",
    "    perturbed_image = image + noise\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)  \n",
    "    return perturbed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a557e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack_performance(net, dataloader, criterion, attack, epsilons, device='cpu'):\n",
    "    \"\"\"Evaluate the model under different noise levels.\"\"\"\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    performances = []\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in dataloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                # Apply the attack\n",
    "                perturbed_images = attack(images, epsilon)\n",
    "                outputs = net(perturbed_images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        avg_loss = test_loss / len(dataloader)\n",
    "        performances.append((epsilon, accuracy, avg_loss))\n",
    "        print(f'For epsilon {epsilon}: Accuracy = {accuracy:.2f}%, Average Loss = {avg_loss:.4f}')\n",
    "\n",
    "    return performances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ab8abfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epsilon 0.01: Accuracy = 29.74%, Average Loss = 1.9614\n",
      "For epsilon 0.05: Accuracy = 29.66%, Average Loss = 1.9623\n",
      "For epsilon 1: Accuracy = 19.87%, Average Loss = 2.2939\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Values of epsilon for noise magnitude\n",
    "epsilons = [0.01, 0.05, 1]\n",
    "\n",
    "# Evaluate the model under noise attacks\n",
    "performances = evaluate_attack_performance(net, testloader, criterion, noise_attack, epsilons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b301bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set up device: Use GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5902eb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss: 1.561\n",
      "Finished Adversarial Training\n"
     ]
    }
   ],
   "source": [
    "def adversarial_training(net, trainloader, criterion, optimizer, epochs=1, epsilon=0.05):\n",
    "    \"\"\"Train the network on clean and adversarial examples.\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass on clean images\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Creating adversarial examples using the noise attack\n",
    "            perturbed_inputs = noise_attack(inputs, epsilon)\n",
    "\n",
    "            # Forward pass on adversarial examples\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(perturbed_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch + 1}: Loss: {running_loss / len(trainloader):.3f}')\n",
    "\n",
    "    print('Finished Adversarial Training')\n",
    "\n",
    "# Assuming net, trainloader, criterion, optimizer are already defined\n",
    "adversarial_training(net, trainloader, criterion, optimizer, epochs=1, epsilon=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "092998aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 2000: Loss: 2.305\n",
      "Epoch 1, Batch 4000: Loss: 2.305\n",
      "Epoch 1, Batch 6000: Loss: 2.306\n",
      "Epoch 1, Batch 8000: Loss: 2.304\n",
      "Epoch 1, Batch 10000: Loss: 2.305\n",
      "Epoch 1, Batch 12000: Loss: 2.305\n",
      "Finished Training\n",
      "Accuracy with noise_attack attack at epsilon=0.05: 11.18%\n",
      "Accuracy with noise_attack attack at epsilon=0.05: 47.14%\n",
      "Accuracy of naturally trained model against attack: 11.18%\n",
      "Accuracy of adversarially trained model against noise attack: 47.14%\n"
     ]
    }
   ],
   "source": [
    "def test_model(net, testloader, attack, epsilon):\n",
    "    \"\"\"Evaluate the model's accuracy under attack.\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            if attack:\n",
    "                images = attack(images, epsilon)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy with {attack.__name__ if attack else \"no\"} attack at epsilon={epsilon}: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "net_natural = Net()  # Assuming a new or reset instance of Net\n",
    "train_network(net_natural, trainloader, criterion, optimizer, epochs=1)  # Train naturally\n",
    "naturally_trained_accuracy = test_model(net_natural, testloader, noise_attack, 0.05)\n",
    "\n",
    "# Use the adversarially trained model\n",
    "adversarially_trained_accuracy = test_model(net, testloader, noise_attack, 0.05)\n",
    "\n",
    "# Output the results\n",
    "print(f'Accuracy of naturally trained model against attack: {naturally_trained_accuracy:.2f}%')\n",
    "print(f'Accuracy of adversarially trained model against noise attack: {adversarially_trained_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e0b7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e8e5ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy under C-W attack with 3 iterations: 19.96%\n",
      "Accuracy under C-W attack with 7 iterations: 6.41%\n",
      "Accuracy under C-W attack with 12 iterations: 1.59%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 19.96), (7, 6.41), (12, 1.59)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_cw_attack_iterations(net, testloader, device, iterations_list):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    results = []\n",
    "    \n",
    "    for max_iter in iterations_list:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            perturbed_images = cw_attack(net, images, labels, device, max_iter=max_iter)\n",
    "            \n",
    "            outputs = net(perturbed_images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Accuracy under C-W attack with {max_iter} iterations: {accuracy:.2f}%')\n",
    "        results.append((max_iter, accuracy))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Test with varying iterations\n",
    "iteration_counts = [3, 7, 12]\n",
    "test_cw_attack_iterations(net, testloader, device, iteration_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d488a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy under C-W attack with 3 iterations: 26.46%\n",
      "Accuracy under C-W attack with 7 iterations: 24.16%\n",
      "Accuracy under C-W attack with 20 iterations: 24.92%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 26.46), (7, 24.16), (20, 24.92)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def cw_attack(model, images, labels, device, max_iter=1000, c=1e-4):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Get original images and labels on the correct device\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    \n",
    "    perturbation = torch.zeros_like(images, requires_grad=True).to(device)\n",
    "    \n",
    "    # Set up optimizer for the perturbation\n",
    "    optimizer = torch.optim.Adam([perturbation], lr=0.01)\n",
    "    \n",
    "    # Define the target class as the least likely predicted class by the model (untargeted attack)\n",
    "    target_labels = labels\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Add perturbation to images and clip to ensure valid pixel range\n",
    "        adv_images = images + perturbation\n",
    "        adv_images = torch.clamp(adv_images, 0, 1)\n",
    "        \n",
    "        # Calculate loss\n",
    "        outputs = model(adv_images)\n",
    "        real = (outputs.gather(1, labels.unsqueeze(1)).squeeze(1))\n",
    "        other = (outputs.max(1)[0] - 1000 * (labels == outputs.max(1)[1]).float())\n",
    "        f = torch.clamp(other - real + 10, min=0)  # 10 is kappa (confidence)\n",
    "        loss = torch.sum(perturbation ** 2) + c * torch.sum(f)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Return the perturbed images\n",
    "    return adv_images.detach()\n",
    "\n",
    "# Example usage in your testing function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "iteration_counts = [3, 7, 20]\n",
    "test_cw_attack_iterations(net, testloader, device, iteration_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "62f286d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training(net, trainloader, criterion, optimizer, device, epochs=1):\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Generate adversarial examples\n",
    "            perturbed_inputs = cw_attack(net, inputs, labels, device, max_iter=10)\n",
    "            \n",
    "            # Forward pass with adversarial examples\n",
    "            outputs = net(perturbed_inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 2000 == 0:  # print every 2000 mini-batches\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}: Loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "    print('Finished Adversarial Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0449333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_under_attack(net, testloader, device, iterations_list):\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    results = []\n",
    "    \n",
    "    for max_iter in iterations_list:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            perturbed_images = cw_attack(net, images, labels, device, max_iter=max_iter)\n",
    "            \n",
    "            outputs = net(perturbed_images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        results.append((max_iter, accuracy))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0fe9aae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 2000: Loss: 2.297\n",
      "Epoch 1, Batch 4000: Loss: 2.086\n",
      "Epoch 1, Batch 6000: Loss: 1.858\n",
      "Epoch 1, Batch 8000: Loss: 1.736\n",
      "Epoch 1, Batch 10000: Loss: 1.666\n",
      "Epoch 1, Batch 12000: Loss: 1.599\n",
      "Finished Adversarial Training\n",
      "Accuracy of naturally trained model against C-W attack: 26.46%\n",
      "Accuracy of adversarially trained model against C-W attack: 43.38%\n"
     ]
    }
   ],
   "source": [
    "# Assume 'net' is your model, and 'net_adv' is a new instance of the same model for adversarial training\n",
    "net_adv = Net()  # Re-instantiate if needed\n",
    "net_adv.to(device)\n",
    "optimizer_adv = optim.SGD(net_adv.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Natural training (already provided above)\n",
    "# Adversarial training\n",
    "adversarial_training(net_adv, trainloader, criterion, optimizer_adv, device, epochs=1)\n",
    "\n",
    "# Evaluate both models\n",
    "iterations_list = [3]  # Adjust as needed for more thorough testing\n",
    "accuracy_natural = evaluate_model_under_attack(net, testloader, device, iterations_list)\n",
    "accuracy_adv_trained = evaluate_model_under_attack(net_adv, testloader, device, iterations_list)\n",
    "\n",
    "print(f'Accuracy of naturally trained model against C-W attack: {accuracy_natural[0][1]:.2f}%')\n",
    "print(f'Accuracy of adversarially trained model against C-W attack: {accuracy_adv_trained[0][1]:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e19ab479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_attack(model, image, label, device, kappa=0, c=0.1, lr=0.01, max_iter=100):\n",
    "    image = image.detach().to(device)  # Ensure no gradients for the original image\n",
    "    perturbation = torch.zeros_like(image, requires_grad=True, device=device)  # Ensure gradients\n",
    "\n",
    "    optimizer = torch.optim.Adam([perturbation], lr=lr)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        perturbed_image = apply_perturbation_and_preserve_gradients(image, perturbation)\n",
    "        loss = compute_loss(model, perturbed_image, label, kappa, c, perturbation)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    final_perturbed_image = apply_perturbation_and_preserve_gradients(image, perturbation)\n",
    "    return final_perturbed_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c606d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def initialize_perturbation(image, device):\n",
    "    image = image.detach().to(device)\n",
    "    perturbation = torch.zeros_like(image, device=device, requires_grad=True)\n",
    "    return image, perturbation\n",
    "\n",
    "def apply_perturbation_and_preserve_gradients(image, perturbation):\n",
    "    perturbed_image = image + perturbation\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    perturbed_image.requires_grad_(True)  # Ensure gradients are preserved\n",
    "    return perturbed_image\n",
    "\n",
    "def compute_loss(model, perturbed_image, label, kappa, c, perturbation):\n",
    "    model.train()  # Enable training mode for gradient computation\n",
    "    outputs = model(perturbed_image)\n",
    "    real_class_logits = outputs.gather(1, label.unsqueeze(1)).squeeze(1)\n",
    "    max_other_logits = (outputs - 1e4 * torch.eye(10, device=perturbed_image.device)[label]).max(1)[0]\n",
    "    cw_loss = torch.clamp(real_class_logits - max_other_logits + kappa, min=0).mean()\n",
    "    l2_loss = c * torch.norm(perturbation)\n",
    "    total_loss = cw_loss + l2_loss\n",
    "    model.eval()  # Switch back to evaluation mode\n",
    "    return total_loss\n",
    "\n",
    "def cw_attack(model, image, label, device, kappa=0, c=0.1, lr=0.01, max_iter=100):\n",
    "    image, perturbation = initialize_perturbation(image, device)\n",
    "    optimizer = torch.optim.Adam([perturbation], lr=lr)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        perturbed_image = apply_perturbation_and_preserve_gradients(image, perturbation)\n",
    "        loss = compute_loss(model, perturbed_image, label, kappa, c, perturbation)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    final_perturbed_image = apply_perturbation_and_preserve_gradients(image, perturbation)\n",
    "    return final_perturbed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39f32b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65a163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa416a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
